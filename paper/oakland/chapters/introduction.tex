\section{Introduction}

\newcounter{intr}
\renewcommand\yphn[1]{\stepcounter{intr} \textcolor{blue} {\theintr.} \yphl{#1}}

\yphn{Memory errors}

According to a recent report that examining 25 years of vulnerabilities (from 1998 to 2012),
buffer overflow causes 14 percent of software security vulnerabilities and 35 percent of critical vulnerabilities,
making it the leading cause of software security vulnerabilities overall.

As of July 2014, the TIOBE index indicates that the C programming language,
which is the language most commonly associated with buffer overflows,
is the most popular language with 17.1 percent of the market.
Embedded systems, network stacks, networked applications, and high-performance computing rely heavily upon C.


Address sanitizer is major buffer overflow prevention mechaniesm.
It works by xxx.


Because C/C++ focuses on performance and being close to the hardware,
there are gramma sugars that can do bounds checks on array references and pointer dereferences are not part of the language.

This can done with the help of compiler.
This should be calacualtes dynamicially.
If the user desires bounds checking, then for the memory accesses that cannot be resolved at compile time, the compiler must insert additional instructions into the generated code to perform the checks.


The time the processor takes to execute those extra instructions at run time is the performance overhead of a bounds checking mechanism.
The runtime overheade.



\yphn{Sanitizer Introduction}
Memory sanitizer refers to a wide range of techniques that ensure memory integrity and confidentiality,
i.e. memory access should not break memory layout unintentionally and read/write data regions unexpectedly.

There are a lot of memory sanitizers have been proposed.

Memory sanitizers are very useful.
ASan helps fuzzing tool found uncountable program bugs.

Memory sanitizers of course can detect memory errors that overwrite function pointers,
therefore they also can mitigate control-flow hijacking attacks.
Compared with control-flow integrity schemes,
memory sanitizers can prevent the attack one step earlier as they act before a malicious code point is activated.


\yphn{Problems of Address Sanitizer: Performance}
However, memory sanitizers are always complained about because of their higher performance overhead.

Asan introduces a performance overhead around two times.

I have found that many researchers report excellent low overheads for automated buffer overflow elimination schemes while in practical use they are actually substantially higher. For example, one set of researchers may report very low overheads by taking advantage of a trap on misaligned memory accesses, but many processors do not trap when dereferencing misaligned pointers. As a result, the check for misalignment must be performed by software, which causes a much higher overhead. Another set of researchers may use a shadow memory by dividing up the address space for the program and for the overflow checking. Again, this may not work in the practical domain because it requires operating system modifications.

We need practical solutons.
I investigated what performance could be achieved in the practical realm and how that performance could be improved for deployment of an automated, compiler-based memory safety checking tool.

\yphn{Existing Perf Optimization Schemes}
Use low-fat pointers. But introduce compatibility problems.
They should carefully support the mathematics operations on data pointers.

The overhead is mainly due to the high-frequency validity checking inside loops.

Move checks outside of loops. But there are no easy ways to identify complex loops.


\yphn{Our Scheme}
This work introduces a new scheme to reduce memory checking frequency,
it is orthogonal to existing schemes that move checkers outside of a loop.

The key idea is a hop-checking algorithm based on a red-zoned memory layout.
In this work, the concept of red-zone has the same meaning as it in the Asan,
i.e. data items are isolated with red-zones which are not allowed to read and write by vanilla program code.

Differently, in this work red-zones are filled with special data (suppose all 0xcc).
Therefore, invalid memory writes on red-zone areas would overwrite the special data,
thus can be detected by checking the integrity of red-zones.
Invalid reads would not leave any footprint, thus if want to detect them should check every memory read access on the spot.

Our scheme employs the principle of locality of data access.
Our hop-checking algorithm guarantees that memory accesses cannot cross the red-zones to destroy other data.
For each data pointer, we create a shadow to remember one of its historical values, i.e. whether it has already accessed.
A naive algorithm may not make use of the shadow value,
simply checking the data pointer once it is used to do memory access.
This algorithm works like the basic configuration of Asan, thus it would introduce high overhead.
On the other hand, our hop-checking algorithm checks the data pointer only when it moves forward or backward away from the shadow value beyond a threshold.
Suppose the threshold value is the size of a red-zone chunk, denoted as $REDZONE\_SIZE$.
Once the security checking is activated, it does security checks as most other address sanitizers do.
Meanwhile, it also backups the current value of the data pointer into the shadow,
preparing to trigger another checking in the next cycle.

Note that, we intentionally make the shadow not be initialized.
In such a way, it would store a randomized value, thus the data pointer always points to a memory address far away from such a  randomized value,
thus the data pointer would be checked at the first time it is used to access memory.

Briefly, every checking ensures that the following memory access would not cross over the red-zones to destroy other data regions.
However, they may read/write the red-zones.
As described above, writes to red-zones would be detected by checking the integrity of red-zones.
Reads to red-zones have a probability to escape from checking.
This can be mitigated by checking the last read access.

Because of the hop-skipping algorithm, we can reduce the frequency of memory checking, thus improve the performance.
This is very efficient for loops with small steps. For example, if the step is 1 as for a byte, and the $REDZONE\_SIZE$
equals to 32, then the overhead is reduced almost  32 times. Thus, it can improve the performance dramatically.

We use an LLVM pass to identify all the data pointers and create their shadows.


To shadow the variables,

We need to know the pointers.

It works like adjusting the source code. to enrich the source code.
1. How to identify data pointers;
2. How to instrument; base on LLVM; This should be accomplished by front-end.
3. How to do check;
4. The affection of compiler optimization.

In the front-end, we identify all the data pointers.
If the data pointer accesses memory, whether read or write, we create another pointer as a shadow.
This shadow is not used for access memory but used as a conditional trigger to do memory security checking.


Currently, We implementable this algorithm with source code.

\yphn{Why Asan High overhead}
For each memory access, it does checks?
Does it neccessary?

\yphn{How we reduce the overhead}
Access array elements and structu memmbers, the checking frequency can be reduced.

We improve th perforammcne by reduce checking freq3ucney to arrayes and structs.

Before teh checks, we
The core,

We depends a xxx on memory layout.
Data elements layout. Each elememt  with a trailing redzone.
For overflow.

How to do quick memory checking?

We create a red-zone around an element, the red-zone stores cookies (i.e. special data).
When there is overhead, it can be detected.
The data elelment are also aligned to a special address.
So we create element from different memroy region. just as low-fat.
So we can detect the start address with simple rounding down to a doubdanry.



Each checking ensure that current address is away from a red-zone.
So the


In this work with a memroy to the last checked memory address.
For each veariblae.

So for each memroy access, it can be deduced to an variable that access the emmroy.

For the value -set analsys. We know each instrauction would
access a set of memory address and a set of values.

Accodding to a compile top-down compiling process. SSA
This insruction is converted from a certain expression.
Which has a convertain semantic meansing in developoing langugen-level.
This memroy address?
access different data elementss at different iteration.

With historical knowledge. store the last checked adderss.
If the distance bwttten teh new addares and the lastst checked address is inside a bounary, i,..e. less than the size of
a red-zone.
We use a variable size of read-zone.
Or use a fixed size read-zone?
This is a trade of perforamnce with memory overhead. Currently, we use fixed size of redzones.
to reduce the complexity.

For each memory address access, we create a temoroy vairable to reambemer its last checked addresses.
When the progress on goning, if the new address is byond the gap, they we check it again.
around 2x memory ovrehead. The stride.

Why our method works? Because of array access?

It is easy for head varibles when we can control the memory allocator.
We can use a table to get its size,

If we use variable size of redzone, then how to create red-zone for stack buffers.

Use historcal values, we can avoid some problems.

\yphn{We need a profiling process}
We detect how does the memory access patterns.
How many memroy bufffers, how many objects.

Optimization for object access.

So we need some IR exampple to observe.


For loops, one is to hoist the memory check outside of loops.
But what about object access?

Can be hoist outside a loop.

Optimize object access checking.

An optimziation to address sanitizer:
Reduce the  checking fraeuncy.


We use variable size of redzones.Small memory overhead. 2x.
This can be achieved by hoist the checking outside of loops. But it difficult for xxx.
Each history address.

For object, we need that the object is checked.
$p->x$ and $p->y$ checked only once.

Why we can do it?
Why hoist checks outside loops? what is the challenged.

access data elements? How to hoist?

Do some kinds of tests before checking?

We also need to find out the challegnes to hoist checks outside loops?


Data memeber access?

For simplicity, we first ignore stack buffers.

There are my load and store instructions applied on the stack local variables.


% \begin{minted}[fontsize=\scriptsize,frame=single,linenos,xleftmargin=10pt,numbersep=-10pt]{cpp}
\begin{minted}[fontsize=\scriptsize,frame=single,xleftmargin=10pt]{cpp}
void foo(char *p) { while(*p){global_sum += *p; p++;} }
\end{minted}
The generated binary code contains two memory checks for the loop or optimiztion-level.
Altugho it can optimized to contail one check for optimize-level O2.
It is still.
In semantic, this is an array access. It can be optimized.




Expore the solutions to recude the frequence of checks.

Array access and object access.

Our naive optimization, can only optimize acces to arrarys.

But we provie optimizatin to objects.

Create Redzone inside an object. to detect internal overflow.

Maybe internal overflow is very importnt.
We can enable it.



If don't need to optimize.
Code usally contains If they are many access to diffiernt fields of the ame object in the same block.
So we can check it only.


We provide flags to control the optimzation.
If need to detect

How to deal with internal object overflow? ovverrite internal function pointers.
Lowfat cannot do it!


Existing DBI tool can count the excuted memory access, but they lack of the semantic information.
We want to know what it is accessed, access an array element, a pointer derefernece, or strucutre member.


\yphn{Contributions}
This work made the following contributions:

\begin{itemize}
  \item A new method to bounds-checking elimination: Symbolic Address-set analysis
  \item A symbolic execution engine on LLVM-IR.
  \item A prototype of semantic-aware address sanitizer.
  \item Detailed evaluations on SPECint.
\end{itemize}


To array access.
Try to hoist the check outside the loops.
However, it is not easy to identify.
The conditions are very harsh.

But for struct memory access, no optimiztion.

To do check at every memory access.

We can employ the checks with modifycation to
datalayout.

Memory access can be expected mode.


\yphn{Ground truth against Asan}

\yphn{Problem Analysis}

\yphn{Optimization suggestion}

\yphn{Problem of existing solutions}

\yphn{Our solution}


\yphn{xxx conclusion}

In addition to hoisting bounds checks out of loops, I also tried to hoist them out of functions. I reasoned that if I hoisted a bounds check into the caller, there might be information in the calling function to reveal the size of the objects, eliminating the need for a bounds check.


There is hope that automated buffer overflow checking will one day perform fast enough to work in future performance-critical systems.


Intel called "MPX" Memory Protection Extensions. Once Intel installs those hardware improvements, it is possible that we will be able to use compiler enforced buffer overflow elimination on performance-critical code as well.

The key problem is bound checking elimination.

\yphn{What kinds of elimination skills have alredy been applied on Asan}

The goal of this work is to reduce the checking frequency on accessing array elements and struct members.
The problem can be classified as boundary checking elimination. In fact, the goal is very simple:
```
if (isFarAway(p, p_lastchk)) {
    if (isOOB(p)) error();
    p_lastchk = p;
  }
```

Even though this problem sounds old, but not solved well.
Existing solutions that hoist the checking outside loops, or split the loops into several parts, do not work well.
These solutions try to be perfect, but once their assumptions do not meet, they do nothing.
Their flaws can be reflected by the implementation of Asan.
For the following code snippet. Asan checks each memory access.
```while(*p) {globalx +=*p, p++;}```

This project would apply IR-level symbolic address-set analysis, to collect symbolic-addresses accessed by each IR instruction.
Then use heuristic rules to find out patterns on accessing arrays and structs.
Once get all these patterns, we can eliminate checks accordingly.

The symbolic analysis algorithms are roughly designed according to my experience and early exploration.
Now, need to be implemented.


\yphn{Contributions}
This work made the following contributions:

\begin{itemize}
  \item A semantic-aware address sanitizing scheme which aims to reduce the bounds-checking frequency.  For array element access, struct member and pointer deference applies We care about three kinds of memory accesses and apply different policies on different access.
  \item A semantic-aware address sanitizer.
  \item A prototype implmentation of profiler.
  \item A prototype implementation of sanitizer.
  \item Detailed evaluations on SPEC.
\end{itemize}

We care about three kinds of memory accesses and apply different policies on different access.

\subsection{Asan \& Lowfat}
Therefore, we need to study Lowfat and Asan first.


% An IR instruction:
% {In-mems, out-mem, vout, vins, scope}

% Do we need to consider the scope?

% while() {
%     basic block;
%   }

% S_{inm}(I)
% S_{outm}(I)
% S_{mem}(I) = S_{inm}(I) U S_{outm}(I)

% V_{outv}(I)
% V_{inv}(I)
% V_{val}{I} = V_{outv}(I) U V_{inv}(I)

% S_{mem}{I} = {p, p+v, p+2*v, p+3*v}
% Arracy access:
% isFarAway(p, p_lastchk) && isOOB(ptr)

% S_{mem}{I} = {p, p+v, p+3v}
% S_{mem}{I'} = {p+v, p+2*v}


% Object access:
% isObj(ptr, type)

% Pointer defreence
% isOOB(ptr)


% init(func)
% for bb in func:
% bb = {}
% SI = {}



% for BB in F:
% if hasNewMS(BB):
%   execFunc(BB)

%   execFunc(BB)
%   {
%   for I in bb:
%   switch(op(I)) {
%       case op(I):
%       v_out = op(I, vins)
%       break;
%       case ...
%     }
%   V_{outv}.add{v_out}
%   v_{inm}.add{inm(I, v_ins)}
%   v_{outm}.add(outm(I, v_out))

%   S_{machine} = {R=xxx, M=xxx}

%       for suc in succssor(bb):
%       merge(SM_{suc}, S)
%     }
