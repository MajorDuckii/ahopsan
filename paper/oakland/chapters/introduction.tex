\section{Introduction}

\newcounter{intr}
\renewcommand\yphn[1]{\stepcounter{intr} \textcolor{blue} {\theintr.} \yphl{#1}}

\yphn{Sanitizer Introduction}
Memory sanitizer refers to a wide range of techniques that ensure memory integrity and confidentiality,
i.e. memory access should not break memory layout unintentionally and read/write data regions unexpectedly.

There are a lot of memory sanitizers have been proposed.

Memory sanitizers are very useful.
ASan helps fuzzing tool found uncountable program bugs.

Memory sanitizers of course can detect memory errors that overwrite function pointers,
therefore they also can mitigate control-flow hijacking attacks.
Compared with control-flow integrity schemes,
memory sanitizers can prevent the attack one step earlier as they act before a malicious code point is activated.


\yphn{Problems of Address Sanitizer: Performance}
However, memory sanitizers are always complained about because of their higher performance overhead.

Asan introduces a performance overhead around two times.

\yphn{Existing Perf Optimization Schemes}
Use low-fat pointers. But introduce compatibility problems.
They should carefully support the mathematics operations on data pointers.

The overhead is mainly due to the high-frequency validity checking inside loops.

Move checks outside of loops. But there are no easy ways to identify complex loops.


\yphn{Our Scheme}
This work introduces a new scheme to reduce memory checking frequency,
it is orthogonal to existing schemes that move checkers outside of a loop.

The key idea is a hop-checking algorithm based on a red-zoned memory layout.
In this work, the concept of red-zone has the same meaning as it in the Asan,
i.e. data items are isolated with red-zones which are not allowed to read and write by vanilla program code.

Differently, in this work red-zones are filled with special data (suppose all 0xcc).
Therefore, invalid memory writes on red-zone areas would overwrite the special data,
thus can be detected by checking the integrity of red-zones.
Invalid reads would not leave any footprint, thus if want to detect them should check every memory read access on the spot.

Our scheme employs the principle of locality of data access.
Our hop-checking algorithm guarantees that memory accesses cannot cross the red-zones to destroy other data.
For each data pointer, we create a shadow to remember one of its historical values, i.e. whether it has already accessed.
A naive algorithm may not make use of the shadow value,
simply checking the data pointer once it is used to do memory access.
This algorithm works like the basic configuration of Asan, thus it would introduce high overhead.
On the other hand, our hop-checking algorithm checks the data pointer only when it moves forward or backward away from the shadow value beyond a threshold.
Suppose the threshold value is the size of a red-zone chunk, denoted as $REDZONE\_SIZE$.
Once the security checking is activated, it does security checks as most other address sanitizers do.
Meanwhile, it also backups the current value of the data pointer into the shadow,
preparing to trigger another checking in the next cycle.

Note that, we intentionally make the shadow not be initialized.
In such a way, it would store a randomized value, thus the data pointer always points to a memory address far away from such a  randomized value,
thus the data pointer would be checked at the first time it is used to access memory.

Briefly, every checking ensures that the following memory access would not cross over the red-zones to destroy other data regions.
However, they may read/write the red-zones.
As described above, writes to red-zones would be detected by checking the integrity of red-zones.
Reads to red-zones have a probability to escape from checking.
This can be mitigated by checking the last read access.

Because of the hop-skipping algorithm, we can reduce the frequency of memory checking, thus improve the performance.
This is very efficient for loops with small steps. For example, if the step is 1 as for a byte, and the $REDZONE\_SIZE$
equals to 32, then the overhead is reduced almost  32 times. Thus, it can improve the performance dramatically.

We use an LLVM pass to identify all the data pointers and create their shadows.


To shadow the variables,

We need to know the pointers.

It works like adjusting the source code. to enrich the source code.
1. How to identify data pointers;
2. How to instrument; base on LLVM; This should be accomplished by front-end.
3. How to do check;
4. The affection of compiler optimization.

In the front-end, we identify all the data pointers.
If the data pointer accesses memory, whether read or write, we create another pointer as a shadow.
This shadow is not used for access memory but used as a conditional trigger to do memory security checking.


Currently, We implementable this algorithm with source code.

\yphn{Why Asan High overhead}
For each memory access, it does checks?
Does it neccessary?

\yphn{How we reduce the overhead}
Access array elements and structu memmbers, the checking frequency can be reduced.

We improve th perforammcne by reduce checking freq3ucney to arrayes and structs.

Before teh checks, we
The core,

We depends a xxx on memory layout.
Data elements layout. Each elememt  with a trailing redzone.
For overflow.

How to do quick memory checking?

We create a red-zone around an element, the red-zone stores cookies (i.e. special data).
When there is overhead, it can be detected.
The data elelment are also aligned to a special address.
So we create element from different memroy region. just as low-fat.
So we can detect the start address with simple rounding down to a doubdanry.



Each checking ensure that current address is away from a red-zone.
So the


In this work with a memroy to the last checked memory address.
For each veariblae.

So for each memroy access, it can be deduced to an variable that access the emmroy.

For the value -set analsys. We know each instrauction would
access a set of memory address and a set of values.

Accodding to a compile top-down compiling process. SSA
This insruction is converted from a certain expression.
Which has a convertain semantic meansing in developoing langugen-level.
This memroy address?
access different data elementss at different iteration.

With historical knowledge. store the last checked adderss.
If the distance bwttten teh new addares and the lastst checked address is inside a bounary, i,..e. less than the size of
a red-zone.
We use a variable size of read-zone.
Or use a fixed size read-zone?
This is a trade of perforamnce with memory overhead. Currently, we use fixed size of redzones.
to reduce the complexity.

For each memory address access, we create a temoroy vairable to reambemer its last checked addresses.
When the progress on goning, if the new address is byond the gap, they we check it again.
around 2x memory ovrehead. The stride.

Why our method works? Because of array access?

It is easy for head varibles when we can control the memory allocator.
We can use a table to get its size,

If we use variable size of redzone, then how to create red-zone for stack buffers.

Use historcal values, we can avoid some problems.

\yphn{We need a profiling process}
We detect how does the memory access patterns.
How many memroy bufffers, how many objects.

Optimization for object access.

So we need some IR exampple to observe.


For loops, one is to hoist the memory check outside of loops.
But what about object access?

Can be hoist outside a loop.

Optimize object access checking.

An optimziation to address sanitizer:
Reduce the  checking fraeuncy.


We use variable size of redzones.Small memory overhead. 2x.
This can be achieved by hoist the checking outside of loops. But it difficult for xxx.
Each history address.

For object, we need that the object is checked.
$p->x$ and $p->y$ checked only once.

Why we can do it?
Why hoist checks outside loops? what is the challenged.

access data elements? How to hoist?

Do some kinds of tests before checking?

We also need to find out the challegnes to hoist checks outside loops?


Data memeber access?

For simplicity, we first ignore stack buffers.

There are my load and store instructions applied on the stack local variables.


% \begin{minted}[fontsize=\scriptsize,frame=single,linenos,xleftmargin=10pt,numbersep=-10pt]{cpp}
\begin{minted}[fontsize=\scriptsize,frame=single,xleftmargin=10pt]{cpp}
void foo(char *p) { while(*p){global_sum += *p; p++;} }
\end{minted}
The generated binary code contains two memory checks for the loop or optimiztion-level.
Altugho it can optimized to contail one check for optimize-level O2.
It is still.
In semantic, this is an array access. It can be optimized.




Expore the solutions to recude the frequence of checks.

Array access and object access.

Our naive optimization, can only optimize acces to arrarys.

But we provie optimizatin to objects.

Create Redzone inside an object. to detect internal overflow.

Maybe internal overflow is very importnt.
We can enable it.



If don't need to optimize.
Code usally contains If they are many access to diffiernt fields of the ame object in the same block.
So we can check it only.


We provide flags to control the optimzation.
If need to detect

How to deal with internal object overflow? ovverrite internal function pointers.
Lowfat cannot do it!


Existing DBI tool can count the excuted memory access, but they lack of the semantic information.
We want to know what it is accessed, access an array element, a pointer derefernece, or strucutre member.


\yphn{Contributions}
This work made the following contributions:

\begin{itemize}
    \item A semantic-aware memory access profiler.
    \item A semantic-aware address sanitizer.
    \item A prototype implmentation of profiler.
    \item A prototype implementation of sanitizer.
    \item Detailed evaluations on SPEC.
\end{itemize}


To array access.
Try to hoist the check outside the loops.
However, it is not easy to identify.
The conditions are very harsh.

But for struct memory access, no optimiztion.

To do check at every memory access.

We can employ the checks with modifycation to
datalayout.

Memory access can be expected mode.

\yphn{Ground truth against Asan}

\yphn{Problem Analysis}

\yphn{Optimization suggestion}

\yphn{Problem of existing solutions}

\yphn{Our solution}



